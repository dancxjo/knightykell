[hosts]

[hosts.brainstem]
image = "rpi"
services = ["voice"]
[hosts.brainstem.hrs04]
trig_pin = 17
echo_pin = 27

[hosts.cerebellum]
image = "ubuntu"
model="pi5"
services = ["voice", "logticker", "display", "asr", "chat"]
[hosts.cerebellum.display]
topics = ["/chat", "/asr", "/logs"]
driver = "sh1106"
width = 128
height = 64
port = 1
address = "0x3C"
rotate = 0
h_offset = 2
[hosts.cerebellum.asr]
model = "tiny"

[hosts.cerebellum.chat]
# Optional system prompt that seeds the conversation
prompt = "You are a concise robot assistant."
backend = "llama"  # prefer local llama-cpp-python over Ollama
# timeout = 30
gguf_url = "https://huggingface.co/bartowski/Phi-3.5-mini-instruct-GGUF/resolve/main/Phi-3.5-mini-instruct-Q4_K_M.gguf"


[hosts.latimer]
services = ["voice", "logticker"]

[hosts.forebrain]
services = ["voice", "logticker"]

[hosts.monitor]
image = "rpi"
services = ["voice", "logticker"]
