[hosts]

[hosts.brainstem]
image = "rpi"
services = ["voice"]
[hosts.brainstem.hrs04]
trig_pin = 17
echo_pin = 27

[hosts.cerebellum]
image = "ubuntu"
model="pi5"
services = ["voice", "logticker", "display", "asr", "create"]
[hosts.cerebellum.display]
topics = ["/asr", "/logs", "/vad"]
driver = "sh1106"
width = 128
height = 64
port = 1
address = "0x3C"
rotate = 0
h_offset = 2
[hosts.cerebellum.asr]
model = "tiny"

[hosts.cerebellum.create]
# Adjust to match the AutonomyLab stack youâ€™ve cloned
package = "create_robot"           # e.g., create_robot or create_bringup
launch_file = "bringup.launch.py"  # e.g., bringup.launch.py or minimal.launch.py
port = "/dev/ttyUSB0"             # serial port for the Create base
# params = { frame_id = "base_link" }
# args = ["--ros-args", "-p", "foo:=bar"]

[hosts.forebrain]
services = ["voice", "logticker", "chat", "asr_long"]
[hosts.forebrain.asr_long]
model = "large-v2"

[hosts.forebrain.chat]
# Optional system prompt that seeds the conversation
prompt = "You are a robot named Pete Knightykell."
backend = "llama"  # prefer local llama-cpp-python over Ollama
# timeout = 30
gguf_url = "https://huggingface.co/bartowski/Phi-3.5-mini-instruct-GGUF/resolve/main/Phi-3.5-mini-instruct-Q4_K_M.gguf"


[hosts.monitor]
image = "rpi"
services = ["voice", "logticker"]
