[hosts]

[hosts.brainstem]
image = "rpi"
services = ["voice"]
[hosts.brainstem.hrs04]
trig_pin = 17
echo_pin = 27

[hosts.cerebellum]
image = "ubuntu"
model="pi5"
services = ["voice", "logticker", "logsummarizer", "display", "asr", "chat"]
[hosts.cerebellum.display]
topics = ["/display", "/chat", "/asr"]
driver = "sh1106"
width = 128
height = 64
port = 1
address = "0x3C"
rotate = 0
h_offset = 2
[hosts.cerebellum.asr]
model = "tiny"

[hosts.cerebellum.chat]
# Optional system prompt that seeds the conversation
prompt = "You are a concise robot assistant."
# Optional: choose backend
# ollama_model = "llama3.2:1b-instruct"
# gguf_url = "https://huggingface.co/TheBloke/Meta-Llama-3.2-1B-Instruct-GGUF/resolve/main/Meta-Llama-3.2-1B-Instruct.Q4_K_M.gguf?download=true"


[hosts.latimer]
services = ["voice", "logticker", "logsummarizer"]

[hosts.forebrain]
services = ["voice", "logticker", "logsummarizer"]

[hosts.monitor]
image = "rpi"
services = ["voice", "logticker", "logsummarizer"]
